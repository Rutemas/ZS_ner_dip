/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
usage: launch.py [-h] [--nnodes NNODES] [--nproc-per-node NPROC_PER_NODE]
                 [--rdzv-backend RDZV_BACKEND] [--rdzv-endpoint RDZV_ENDPOINT]
                 [--rdzv-id RDZV_ID] [--rdzv-conf RDZV_CONF] [--standalone]
                 [--max-restarts MAX_RESTARTS]
                 [--monitor-interval MONITOR_INTERVAL]
                 [--start-method {spawn,fork,forkserver}] [--role ROLE] [-m]
                 [--no-python] [--run-path] [--log-dir LOG_DIR] [-r REDIRECTS]
                 [-t TEE] [--node-rank NODE_RANK] [--master-addr MASTER_ADDR]
                 [--master-port MASTER_PORT] [--local-addr LOCAL_ADDR]
                 [--use-env]
                 training_script ...
launch.py: error: argument --node-rank/--node_rank: invalid int value: ''
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
usage: launch.py [-h] [--nnodes NNODES] [--nproc-per-node NPROC_PER_NODE]
                 [--rdzv-backend RDZV_BACKEND] [--rdzv-endpoint RDZV_ENDPOINT]
                 [--rdzv-id RDZV_ID] [--rdzv-conf RDZV_CONF] [--standalone]
                 [--max-restarts MAX_RESTARTS]
                 [--monitor-interval MONITOR_INTERVAL]
                 [--start-method {spawn,fork,forkserver}] [--role ROLE] [-m]
                 [--no-python] [--run-path] [--log-dir LOG_DIR] [-r REDIRECTS]
                 [-t TEE] [--node-rank NODE_RANK] [--master-addr MASTER_ADDR]
                 [--master-port MASTER_PORT] [--local-addr LOCAL_ADDR]
                 [--use-env]
                 training_script ...
launch.py: error: argument --node-rank/--node_rank: invalid int value: ''
/usr/bin/python3: No module named torchrun
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
usage: launch.py [-h] [--nnodes NNODES] [--nproc-per-node NPROC_PER_NODE]
                 [--rdzv-backend RDZV_BACKEND] [--rdzv-endpoint RDZV_ENDPOINT]
                 [--rdzv-id RDZV_ID] [--rdzv-conf RDZV_CONF] [--standalone]
                 [--max-restarts MAX_RESTARTS]
                 [--monitor-interval MONITOR_INTERVAL]
                 [--start-method {spawn,fork,forkserver}] [--role ROLE] [-m]
                 [--no-python] [--run-path] [--log-dir LOG_DIR] [-r REDIRECTS]
                 [-t TEE] [--node-rank NODE_RANK] [--master-addr MASTER_ADDR]
                 [--master-port MASTER_PORT] [--local-addr LOCAL_ADDR]
                 [--use-env]
                 training_script ...
launch.py: error: argument --node-rank/--node_rank: invalid int value: ''
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
usage: launch.py [-h] [--nnodes NNODES] [--nproc-per-node NPROC_PER_NODE]
                 [--rdzv-backend RDZV_BACKEND] [--rdzv-endpoint RDZV_ENDPOINT]
                 [--rdzv-id RDZV_ID] [--rdzv-conf RDZV_CONF] [--standalone]
                 [--max-restarts MAX_RESTARTS]
                 [--monitor-interval MONITOR_INTERVAL]
                 [--start-method {spawn,fork,forkserver}] [--role ROLE] [-m]
                 [--no-python] [--run-path] [--log-dir LOG_DIR] [-r REDIRECTS]
                 [-t TEE] [--node-rank NODE_RANK] [--master-addr MASTER_ADDR]
                 [--master-port MASTER_PORT] [--local-addr LOCAL_ADDR]
                 [--use-env]
                 training_script ...
launch.py: error: argument --node-rank/--node_rank: invalid int value: ''
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
usage: launch.py [-h] [--nnodes NNODES] [--nproc-per-node NPROC_PER_NODE]
                 [--rdzv-backend RDZV_BACKEND] [--rdzv-endpoint RDZV_ENDPOINT]
                 [--rdzv-id RDZV_ID] [--rdzv-conf RDZV_CONF] [--standalone]
                 [--max-restarts MAX_RESTARTS]
                 [--monitor-interval MONITOR_INTERVAL]
                 [--start-method {spawn,fork,forkserver}] [--role ROLE] [-m]
                 [--no-python] [--run-path] [--log-dir LOG_DIR] [-r REDIRECTS]
                 [-t TEE] [--node-rank NODE_RANK] [--master-addr MASTER_ADDR]
                 [--master-port MASTER_PORT] [--local-addr LOCAL_ADDR]
                 [--use-env]
                 training_script ...
launch.py: error: argument --master-port/--master_port: invalid int value: ''
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2024-04-10 19:24:56,931] torch.distributed.run: [WARNING] 
[2024-04-10 19:24:56,931] torch.distributed.run: [WARNING] *****************************************
[2024-04-10 19:24:56,931] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-10 19:24:56,931] torch.distributed.run: [WARNING] *****************************************
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 231, in launch_agent
    master_addr, master_port = _get_addr_and_port(rdzv_parameters)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 171, in _get_addr_and_port
    master_addr, master_port = parse_rendezvous_endpoint(endpoint, default_port=-1)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/utils.py", line 103, in parse_rendezvous_endpoint
    raise ValueError(
ValueError: The hostname of the rendezvous endpoint ':12358' must be a dot-separated list of labels, an IPv4 address, or an IPv6 address.
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
[2024-04-10 19:25:57,794] torch.distributed.run: [WARNING] 
[2024-04-10 19:25:57,794] torch.distributed.run: [WARNING] *****************************************
[2024-04-10 19:25:57,794] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-04-10 19:25:57,794] torch.distributed.run: [WARNING] *****************************************
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 259, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 727, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 862, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 699, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 123, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 542, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 55, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
torch.distributed.DistStoreError: Timed out after 901 seconds waiting for clients. 1/2 clients joined.
/usr/bin/python3: can't open file '/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/train.py': [Errno 2] No such file or directory
[2024-04-10 19:57:57,131] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 380) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_19:57:57
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 380)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 30, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/__init__.py", line 11, in <module>
    from fairseq.criterions.fairseq_criterion import (  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/fairseq_criterion.py", line 9, in <module>
    from fairseq import metrics, utils
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/utils.py", line 20, in <module>
    from fairseq.data import iterators
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/__init__.py", line 23, in <module>
    from .indexed_dataset import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/indexed_dataset.py", line 101, in <module>
    6: np.float,
  File "/home/artem/.local/lib/python3.10/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'cfloat'?
[2024-04-10 19:59:28,700] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 367) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_19:59:28
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 367)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: run.py [-h] [--nnodes NNODES] [--nproc-per-node NPROC_PER_NODE]
              [--rdzv-backend RDZV_BACKEND] [--rdzv-endpoint RDZV_ENDPOINT]
              [--rdzv-id RDZV_ID] [--rdzv-conf RDZV_CONF] [--standalone]
              [--max-restarts MAX_RESTARTS]
              [--monitor-interval MONITOR_INTERVAL]
              [--start-method {spawn,fork,forkserver}] [--role ROLE] [-m]
              [--no-python] [--run-path] [--log-dir LOG_DIR] [-r REDIRECTS]
              [-t TEE] [--node-rank NODE_RANK] [--master-addr MASTER_ADDR]
              [--master-port MASTER_PORT] [--local-addr LOCAL_ADDR]
              training_script ...
run.py: error: argument --node-rank/--node_rank: invalid int value: ''
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 30, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/__init__.py", line 11, in <module>
    from fairseq.criterions.fairseq_criterion import (  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/fairseq_criterion.py", line 9, in <module>
    from fairseq import metrics, utils
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/utils.py", line 20, in <module>
    from fairseq.data import iterators
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/__init__.py", line 23, in <module>
    from .indexed_dataset import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/indexed_dataset.py", line 101, in <module>
    6: np.float,
  File "/home/artem/.local/lib/python3.10/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'cfloat'?
[2024-04-10 20:00:34,469] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 439) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:00:34
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 439)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 30, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/__init__.py", line 11, in <module>
    from fairseq.criterions.fairseq_criterion import (  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/fairseq_criterion.py", line 9, in <module>
    from fairseq import metrics, utils
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/utils.py", line 20, in <module>
    from fairseq.data import iterators
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/__init__.py", line 23, in <module>
    from .indexed_dataset import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/indexed_dataset.py", line 299, in <module>
    class IndexedDatasetBuilder(object):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/indexed_dataset.py", line 306, in IndexedDatasetBuilder
    np.float: 4,
  File "/home/artem/.local/lib/python3.10/site-packages/numpy/__init__.py", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'float'.
`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'cfloat'?
[2024-04-10 20:09:10,444] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 380) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:09:10
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 380)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 30, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/__init__.py", line 11, in <module>
    from fairseq.criterions.fairseq_criterion import (  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/fairseq_criterion.py", line 9, in <module>
    from fairseq import metrics, utils
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/utils.py", line 20, in <module>
    from fairseq.data import iterators
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/__init__.py", line 29, in <module>
    from .language_pair_dataset import LanguagePairDataset
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/language_pair_dataset.py", line 14, in <module>
    import nltk
ModuleNotFoundError: No module named 'nltk'
[2024-04-10 20:10:06,373] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 368) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:10:06
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 368)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 33, in <module>
    import fairseq.optim  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/__init__.py", line 46, in <module>
    importlib.import_module("fairseq.optim." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/composite.py", line 14, in <module>
    from fairseq.optim.lr_scheduler import FairseqLRScheduler, build_lr_scheduler
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/__init__.py", line 36, in <module>
    importlib.import_module("fairseq.optim.lr_scheduler." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py", line 7, in <module>
    from collections import Collection
ImportError: cannot import name 'Collection' from 'collections' (/usr/lib/python3.10/collections/__init__.py)
[2024-04-10 20:12:59,323] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 374) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:12:59
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 374)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 33, in <module>
    import fairseq.optim  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/__init__.py", line 46, in <module>
    importlib.import_module("fairseq.optim." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/composite.py", line 14, in <module>
    from fairseq.optim.lr_scheduler import FairseqLRScheduler, build_lr_scheduler
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/__init__.py", line 36, in <module>
    importlib.import_module("fairseq.optim.lr_scheduler." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py", line 7, in <module>
    from collections import Collection
ImportError: cannot import name 'Collection' from 'collections' (/usr/lib/python3.10/collections/__init__.py)
[2024-04-10 20:13:46,148] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 654) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:13:46
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 654)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 33, in <module>
    import fairseq.optim  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/__init__.py", line 46, in <module>
    importlib.import_module("fairseq.optim." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/composite.py", line 14, in <module>
    from fairseq.optim.lr_scheduler import FairseqLRScheduler, build_lr_scheduler
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/__init__.py", line 36, in <module>
    importlib.import_module("fairseq.optim.lr_scheduler." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/cosine_lr_scheduler.py", line 7, in <module>
    from collections.abc import collection
ImportError: cannot import name 'collection' from 'collections.abc' (/usr/lib/python3.10/collections/abc.py)
[2024-04-10 20:22:20,329] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2008) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:22:20
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2008)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 33, in <module>
    import fairseq.optim  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/__init__.py", line 46, in <module>
    importlib.import_module("fairseq.optim." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/composite.py", line 14, in <module>
    from fairseq.optim.lr_scheduler import FairseqLRScheduler, build_lr_scheduler
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/__init__.py", line 36, in <module>
    importlib.import_module("fairseq.optim.lr_scheduler." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/inverse_square_root_schedule.py", line 6, in <module>
    from collections import Collection
ImportError: cannot import name 'Collection' from 'collections' (/usr/lib/python3.10/collections/__init__.py)
[2024-04-10 20:22:39,862] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2135) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:22:39
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2135)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 33, in <module>
    import fairseq.optim  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/__init__.py", line 46, in <module>
    importlib.import_module("fairseq.optim." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/composite.py", line 14, in <module>
    from fairseq.optim.lr_scheduler import FairseqLRScheduler, build_lr_scheduler
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/__init__.py", line 36, in <module>
    importlib.import_module("fairseq.optim.lr_scheduler." + file_name)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/optim/lr_scheduler/vaswani_lr_scheduler.py", line 6, in <module>
    from collections import Collection
ImportError: cannot import name 'Collection' from 'collections' (/usr/lib/python3.10/collections/__init__.py)
[2024-04-10 20:23:22,807] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 375) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:23:22
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 375)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '256'
[2024-04-10 20:33:01,169] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 380) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:33:01
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 380)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '1024'
[2024-04-10 20:50:46,673] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 381) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_20:50:46
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 381)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '64'
[2024-04-10 21:22:48,660] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 376) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_21:22:48
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 376)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 28, in <module>
    hydra_init()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/dataclass/initialize.py", line 19, in hydra_init
    cs.store(name=cfg_name, node=FairseqConfig)
  File "/home/artem/.local/lib/python3.10/site-packages/hydra/core/config_store.py", line 85, in store
    cfg = OmegaConf.structured(node)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 140, in structured
    return OmegaConf.create(obj, parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 177, in create
    return OmegaConf._create_impl(obj=obj, parent=parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 245, in _create_impl
    format_and_raise(node=None, key=None, value=None, msg=str(e), cause=e)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 694, in format_and_raise
    _raise(ex, cause)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 610, in _raise
    raise ex  # set end OC_CAUSE=1 for full backtrace
omegaconf.errors.ValidationError: Non optional field cannot be assigned None
	full_key: 
	reference_type=None
	object_type=None
[2024-04-10 21:26:49,236] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 375) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_21:26:49
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 375)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 28, in <module>
    hydra_init()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/dataclass/initialize.py", line 19, in hydra_init
    cs.store(name=cfg_name, node=FairseqConfig)
  File "/home/artem/.local/lib/python3.10/site-packages/hydra/core/config_store.py", line 85, in store
    cfg = OmegaConf.structured(node)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 140, in structured
    return OmegaConf.create(obj, parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 177, in create
    return OmegaConf._create_impl(obj=obj, parent=parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 245, in _create_impl
    format_and_raise(node=None, key=None, value=None, msg=str(e), cause=e)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 694, in format_and_raise
    _raise(ex, cause)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 610, in _raise
    raise ex  # set end OC_CAUSE=1 for full backtrace
omegaconf.errors.ValidationError: Non optional field cannot be assigned None
	full_key: 
	reference_type=None
	object_type=None
[2024-04-10 21:50:45,723] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 380) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_21:50:45
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 380)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '32'
[2024-04-10 22:00:10,608] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 375) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_22:00:10
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 375)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '32'
[2024-04-10 22:10:21,595] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 380) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_22:10:21
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 380)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '2048'
[2024-04-10 22:11:08,722] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 380) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_22:11:08
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 380)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '1024'
[2024-04-10 22:23:07,309] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 382) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_22:23:07
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 382)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 28, in <module>
    hydra_init()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/dataclass/initialize.py", line 19, in hydra_init
    cs.store(name=cfg_name, node=FairseqConfig)
  File "/home/artem/.local/lib/python3.10/site-packages/hydra/core/config_store.py", line 85, in store
    cfg = OmegaConf.structured(node)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 140, in structured
    return OmegaConf.create(obj, parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 177, in create
    return OmegaConf._create_impl(obj=obj, parent=parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 245, in _create_impl
    format_and_raise(node=None, key=None, value=None, msg=str(e), cause=e)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 694, in format_and_raise
    _raise(ex, cause)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 610, in _raise
    raise ex  # set end OC_CAUSE=1 for full backtrace
omegaconf.errors.ValidationError: Non optional field cannot be assigned None
	full_key: 
	reference_type=None
	object_type=None
[2024-04-10 22:24:21,156] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 376) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_22:24:21
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 376)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 28, in <module>
    hydra_init()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/dataclass/initialize.py", line 19, in hydra_init
    cs.store(name=cfg_name, node=FairseqConfig)
  File "/home/artem/.local/lib/python3.10/site-packages/hydra/core/config_store.py", line 85, in store
    cfg = OmegaConf.structured(node)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 140, in structured
    return OmegaConf.create(obj, parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 177, in create
    return OmegaConf._create_impl(obj=obj, parent=parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 245, in _create_impl
    format_and_raise(node=None, key=None, value=None, msg=str(e), cause=e)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 694, in format_and_raise
    _raise(ex, cause)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 610, in _raise
    raise ex  # set end OC_CAUSE=1 for full backtrace
omegaconf.errors.ValidationError: Non optional field cannot be assigned None
	full_key: 
	reference_type=None
	object_type=None
[2024-04-10 22:36:10,829] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 387) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_22:36:10
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 387)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '1024.0'
[2024-04-10 22:38:11,747] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 373) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_22:38:11
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 373)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '1024'
[2024-04-10 22:39:39,800] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 371) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-10_22:39:39
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 371)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/usr/local/bin/python3.6: Error while finding module specification for 'torch.distributed.launch' (ModuleNotFoundError: No module named 'torch')
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '1024'
[2024-04-11 20:26:49,038] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 7612) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-11_20:26:49
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 7612)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py:183: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 28, in <module>
    hydra_init()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/dataclass/initialize.py", line 19, in hydra_init
    cs.store(name=cfg_name, node=FairseqConfig)
  File "/home/artem/.local/lib/python3.10/site-packages/hydra/core/config_store.py", line 85, in store
    cfg = OmegaConf.structured(node)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 140, in structured
    return OmegaConf.create(obj, parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 177, in create
    return OmegaConf._create_impl(obj=obj, parent=parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 245, in _create_impl
    format_and_raise(node=None, key=None, value=None, msg=str(e), cause=e)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 694, in format_and_raise
    _raise(ex, cause)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 610, in _raise
    raise ex  # set end OC_CAUSE=1 for full backtrace
omegaconf.errors.ValidationError: Non optional field cannot be assigned None
	full_key: 
	reference_type=None
	object_type=None
[2024-04-11 20:27:42,363] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 7882) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 198, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 194, in main
    launch(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launch.py", line 179, in launch
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-11_20:27:42
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 7882)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 28, in <module>
    hydra_init()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/dataclass/initialize.py", line 19, in hydra_init
    cs.store(name=cfg_name, node=FairseqConfig)
  File "/home/artem/.local/lib/python3.10/site-packages/hydra/core/config_store.py", line 85, in store
    cfg = OmegaConf.structured(node)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 140, in structured
    return OmegaConf.create(obj, parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 177, in create
    return OmegaConf._create_impl(obj=obj, parent=parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 245, in _create_impl
    format_and_raise(node=None, key=None, value=None, msg=str(e), cause=e)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 694, in format_and_raise
    _raise(ex, cause)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 610, in _raise
    raise ex  # set end OC_CAUSE=1 for full backtrace
omegaconf.errors.ValidationError: Non optional field cannot be assigned None
	full_key: 
	reference_type=None
	object_type=None
[2024-04-11 20:28:15,201] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 8039) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-11_20:28:15
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 8039)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 28, in <module>
    hydra_init()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/dataclass/initialize.py", line 19, in hydra_init
    cs.store(name=cfg_name, node=FairseqConfig)
  File "/home/artem/.local/lib/python3.10/site-packages/hydra/core/config_store.py", line 85, in store
    cfg = OmegaConf.structured(node)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 140, in structured
    return OmegaConf.create(obj, parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 177, in create
    return OmegaConf._create_impl(obj=obj, parent=parent)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/omegaconf.py", line 245, in _create_impl
    format_and_raise(node=None, key=None, value=None, msg=str(e), cause=e)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 694, in format_and_raise
    _raise(ex, cause)
  File "/home/artem/.local/lib/python3.10/site-packages/omegaconf/_utils.py", line 610, in _raise
    raise ex  # set end OC_CAUSE=1 for full backtrace
omegaconf.errors.ValidationError: Non optional field cannot be assigned None
	full_key: 
	reference_type=None
	object_type=None
[2024-04-11 21:18:07,976] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 19904) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-11_21:18:07
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 19904)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: 'MAX_TOKENS'
[2024-04-11 21:21:02,491] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 20601) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-11_21:21:02
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 20601)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format LOG_FORMAT]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl DATASET_IMPL]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
train.py: error: argument --max-tokens: invalid Optional value: '1024'
[2024-04-11 21:22:16,947] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 2) local_rank: 0 (pid: 20935) of binary: /usr/bin/python3
Traceback (most recent call last):
  File "/usr/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 816, in <module>
    main()
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-11_21:22:16
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 20935)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "m2m/train.py", line 10, in <module>
    from fairseq_cli.train import cli_main
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 20, in <module>
    from fairseq import (
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/__init__.py", line 30, in <module>
    import fairseq.criterions  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/__init__.py", line 11, in <module>
    from fairseq.criterions.fairseq_criterion import (  # noqa
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/criterions/fairseq_criterion.py", line 9, in <module>
    from fairseq import metrics, utils
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/utils.py", line 20, in <module>
    from fairseq.data import iterators
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/__init__.py", line 29, in <module>
    from .language_pair_dataset import LanguagePairDataset
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/language_pair_dataset.py", line 14, in <module>
    import nltk
ModuleNotFoundError: No module named 'nltk'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 3796) of binary: /usr/bin/python3.7
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 248, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-16_06:53:35
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3796)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format {json,none,simple,tqdm}]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl {raw,lazy,cached,mmap,fasta}]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
                [--activation-fn {relu,gelu,gelu_fast,gelu_accurate,tanh,linear}]
                [--dropout D] [--attention-dropout D] [--activation-dropout D]
                [--encoder-embed-path STR] [--encoder-embed-dim N]
                [--encoder-ffn-embed-dim N] [--encoder-layers N]
                [--encoder-attention-heads N] [--encoder-normalize-before]
                [--encoder-learned-pos] [--decoder-embed-path STR]
                [--decoder-embed-dim N] [--decoder-ffn-embed-dim N]
                [--decoder-layers N] [--decoder-attention-heads N]
                [--decoder-learned-pos] [--decoder-normalize-before]
                [--decoder-output-dim N] [--share-decoder-input-output-embed]
                [--share-all-embeddings] [--no-token-positional-embeddings]
                [--adaptive-softmax-cutoff EXPR]
                [--adaptive-softmax-dropout D] [--layernorm-embedding]
                [--no-scale-embedding] [--checkpoint-activations]
                [--no-cross-attention] [--cross-self-attention]
                [--encoder-layerdrop D] [--decoder-layerdrop D]
                [--encoder-layers-to-keep ENCODER_LAYERS_TO_KEEP]
                [--decoder-layers-to-keep DECODER_LAYERS_TO_KEEP]
                [--quant-noise-pq D] [--quant-noise-pq-block-size D]
                [--quant-noise-scalar D] [-s SRC] [-t TARGET]
                [--lang-pairs PAIRS] [--keep-inference-langtok] [--debug]
                [--sampling-method {uniform,temperature,concat,RoundRobin,linear}]
                [--sampling-temperature SAMPLING_TEMPERATURE]
                [--min-sampling-temperature MIN_SAMPLING_TEMPERATURE]
                [--warmup-epoch WARMUP_EPOCH] [--langs LANGS]
                [--lang-dict LANG_DICT]
                [--lang-tok-style {multilingual,mbart}] [--load-alignments]
                [--left-pad-source BOOL] [--left-pad-target BOOL]
                [--max-source-positions N] [--max-target-positions N]
                [--upsample-primary UPSAMPLE_PRIMARY] [--truncate-source]
                [--encoder-langtok SRCTGT] [--decoder-langtok]
                [--lang-tok-replacing-bos-eos] [--enable-lang-ids]
                [--enable-reservsed-directions-shared-datasets]
                [--same-lang-per-batch] [--extra-data EXTRA_DATA]
                [--extra-lang-pairs EXTRA_LANG_PAIRS]
                [--fixed-dictionary FIXED_DICTIONARY]
                [--langtoks-specs LANGTOKS_SPECS] [--langtoks LANGTOKS]
                [--sampling-weights-from-file SAMPLING_WEIGHTS_FROM_FILE]
                [--sampling-weights SAMPLING_WEIGHTS]
                [--virtual-epoch-size VIRTUAL_EPOCH_SIZE]
                [--virtual-data-size VIRTUAL_DATA_SIZE]
                [--data-param-list-sampling-ratios DATA_PARAM_LIST_SAMPLING_RATIOS]
                [--slot-method {replace,insert,None}] [--slot-prob SLOT_PROB]
                [--max-slot-num MAX_SLOT_NUM]
                [--max-span-length MAX_SPAN_LENGTH]
                [--subword-prob SUBWORD_PROB]
                [--construct-phrase-level-align-dataset]
                [--sentencepiece-model SENTENCEPIECE_MODEL]
                [--label-smoothing D] [--report-accuracy]
                [--ignore-prefix-size IGNORE_PREFIX_SIZE]
                [--adam-betas ADAM_BETAS] [--adam-eps ADAM_EPS]
                [--weight-decay WEIGHT_DECAY] [--use-old-adam]
                [--warmup-updates WARMUP_UPDATES]
                [--warmup-init-lr WARMUP_INIT_LR] [--pad PAD] [--eos EOS]
                [--unk UNK]
                data
train.py: error: unrecognized arguments: --min-lr 1e-7
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 3980) of binary: /usr/bin/python3.7
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 248, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-16_06:54:20
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 3980)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
usage: train.py [-h] [--no-progress-bar] [--log-interval LOG_INTERVAL]
                [--log-format {json,none,simple,tqdm}]
                [--tensorboard-logdir TENSORBOARD_LOGDIR]
                [--wandb-project WANDB_PROJECT] [--seed SEED] [--cpu] [--tpu]
                [--bf16] [--memory-efficient-bf16] [--fp16]
                [--memory-efficient-fp16] [--fp16-no-flatten-grads]
                [--fp16-init-scale FP16_INIT_SCALE]
                [--fp16-scale-window FP16_SCALE_WINDOW]
                [--fp16-scale-tolerance FP16_SCALE_TOLERANCE]
                [--min-loss-scale MIN_LOSS_SCALE]
                [--threshold-loss-scale THRESHOLD_LOSS_SCALE]
                [--user-dir USER_DIR] [--empty-cache-freq EMPTY_CACHE_FREQ]
                [--all-gather-list-size ALL_GATHER_LIST_SIZE]
                [--model-parallel-size MODEL_PARALLEL_SIZE]
                [--quantization-config-path QUANTIZATION_CONFIG_PATH]
                [--profile] [--reset-logging] [--tokenizer {moses,nltk,space}]
                [--bpe {bytes,byte_bpe,characters,fastbpe,gpt2,bert,hf_byte_bpe,sentencepiece,subword_nmt}]
                [--criterion {adaptive_loss,composite_loss,cross_entropy,ctc,label_smoothed_cross_entropy,label_smoothed_cross_entropy_with_alignment,label_smoothed_cross_entropy_with_minimize_distance,label_smoothed_cross_entropy_with_sparse,legacy_masked_lm_loss,masked_lm,model,nat_loss,sentence_prediction,sentence_ranking,wav2vec,vocab_parallel_cross_entropy}]
                [--optimizer {adadelta,adafactor,adagrad,adam,adamax,composite,lamb,nag,sgd}]
                [--lr-scheduler {cosine,fixed,inverse_sqrt,manual,pass_through,polynomial_decay,reduce_lr_on_plateau,triangular,tri_stage,vaswani_inverse_sqrt}]
                [--scoring {sacrebleu,bleu,chrf,wer}] [--task TASK]
                [--num-workers NUM_WORKERS]
                [--skip-invalid-size-inputs-valid-test]
                [--max-tokens MAX_TOKENS] [--batch-size BATCH_SIZE]
                [--required-batch-size-multiple REQUIRED_BATCH_SIZE_MULTIPLE]
                [--required-seq-len-multiple REQUIRED_SEQ_LEN_MULTIPLE]
                [--dataset-impl {raw,lazy,cached,mmap,fasta}]
                [--data-buffer-size DATA_BUFFER_SIZE]
                [--train-subset TRAIN_SUBSET] [--valid-subset VALID_SUBSET]
                [--validate-interval VALIDATE_INTERVAL]
                [--validate-interval-updates VALIDATE_INTERVAL_UPDATES]
                [--validate-after-updates VALIDATE_AFTER_UPDATES]
                [--fixed-validation-seed FIXED_VALIDATION_SEED]
                [--disable-validation] [--max-tokens-valid MAX_TOKENS_VALID]
                [--batch-size-valid BATCH_SIZE_VALID]
                [--curriculum CURRICULUM] [--gen-subset GEN_SUBSET]
                [--num-shards NUM_SHARDS] [--shard-id SHARD_ID]
                [--distributed-world-size DISTRIBUTED_WORLD_SIZE]
                [--distributed-rank DISTRIBUTED_RANK]
                [--distributed-backend DISTRIBUTED_BACKEND]
                [--distributed-init-method DISTRIBUTED_INIT_METHOD]
                [--distributed-port DISTRIBUTED_PORT] [--device-id DEVICE_ID]
                [--distributed-no-spawn] [--ddp-backend {c10d,no_c10d}]
                [--bucket-cap-mb BUCKET_CAP_MB] [--fix-batches-to-gpus]
                [--find-unused-parameters] [--fast-stat-sync]
                [--broadcast-buffers] [--distributed-wrapper {DDP,SlowMo}]
                [--slowmo-momentum SLOWMO_MOMENTUM]
                [--slowmo-algorithm SLOWMO_ALGORITHM]
                [--localsgd-frequency LOCALSGD_FREQUENCY]
                [--nprocs-per-node NPROCS_PER_NODE]
                [--pipeline-model-parallel]
                [--pipeline-balance PIPELINE_BALANCE]
                [--pipeline-devices PIPELINE_DEVICES]
                [--pipeline-chunks PIPELINE_CHUNKS]
                [--pipeline-encoder-balance PIPELINE_ENCODER_BALANCE]
                [--pipeline-encoder-devices PIPELINE_ENCODER_DEVICES]
                [--pipeline-decoder-balance PIPELINE_DECODER_BALANCE]
                [--pipeline-decoder-devices PIPELINE_DECODER_DEVICES]
                [--pipeline-checkpoint {always,never,except_last}]
                [--zero-sharding {none,os}] [--arch ARCH]
                [--max-epoch MAX_EPOCH] [--max-update MAX_UPDATE]
                [--stop-time-hours STOP_TIME_HOURS] [--clip-norm CLIP_NORM]
                [--sentence-avg] [--update-freq UPDATE_FREQ] [--lr LR]
                [--stop-min-lr STOP_MIN_LR] [--use-bmuf] [--save-dir SAVE_DIR]
                [--restore-file RESTORE_FILE]
                [--finetune-from-model FINETUNE_FROM_MODEL]
                [--reset-dataloader] [--reset-lr-scheduler] [--reset-meters]
                [--reset-optimizer]
                [--optimizer-overrides OPTIMIZER_OVERRIDES]
                [--save-interval SAVE_INTERVAL]
                [--save-interval-updates SAVE_INTERVAL_UPDATES]
                [--keep-interval-updates KEEP_INTERVAL_UPDATES]
                [--keep-last-epochs KEEP_LAST_EPOCHS]
                [--keep-best-checkpoints KEEP_BEST_CHECKPOINTS] [--no-save]
                [--no-epoch-checkpoints] [--no-last-checkpoints]
                [--no-save-optimizer-state]
                [--best-checkpoint-metric BEST_CHECKPOINT_METRIC]
                [--maximize-best-checkpoint-metric] [--patience PATIENCE]
                [--checkpoint-suffix CHECKPOINT_SUFFIX]
                [--checkpoint-shard-count CHECKPOINT_SHARD_COUNT]
                [--load-checkpoint-on-all-dp-ranks]
                [--activation-fn {relu,gelu,gelu_fast,gelu_accurate,tanh,linear}]
                [--dropout D] [--attention-dropout D] [--activation-dropout D]
                [--encoder-embed-path STR] [--encoder-embed-dim N]
                [--encoder-ffn-embed-dim N] [--encoder-layers N]
                [--encoder-attention-heads N] [--encoder-normalize-before]
                [--encoder-learned-pos] [--decoder-embed-path STR]
                [--decoder-embed-dim N] [--decoder-ffn-embed-dim N]
                [--decoder-layers N] [--decoder-attention-heads N]
                [--decoder-learned-pos] [--decoder-normalize-before]
                [--decoder-output-dim N] [--share-decoder-input-output-embed]
                [--share-all-embeddings] [--no-token-positional-embeddings]
                [--adaptive-softmax-cutoff EXPR]
                [--adaptive-softmax-dropout D] [--layernorm-embedding]
                [--no-scale-embedding] [--checkpoint-activations]
                [--no-cross-attention] [--cross-self-attention]
                [--encoder-layerdrop D] [--decoder-layerdrop D]
                [--encoder-layers-to-keep ENCODER_LAYERS_TO_KEEP]
                [--decoder-layers-to-keep DECODER_LAYERS_TO_KEEP]
                [--quant-noise-pq D] [--quant-noise-pq-block-size D]
                [--quant-noise-scalar D] [-s SRC] [-t TARGET]
                [--lang-pairs PAIRS] [--keep-inference-langtok] [--debug]
                [--sampling-method {uniform,temperature,concat,RoundRobin,linear}]
                [--sampling-temperature SAMPLING_TEMPERATURE]
                [--min-sampling-temperature MIN_SAMPLING_TEMPERATURE]
                [--warmup-epoch WARMUP_EPOCH] [--langs LANGS]
                [--lang-dict LANG_DICT]
                [--lang-tok-style {multilingual,mbart}] [--load-alignments]
                [--left-pad-source BOOL] [--left-pad-target BOOL]
                [--max-source-positions N] [--max-target-positions N]
                [--upsample-primary UPSAMPLE_PRIMARY] [--truncate-source]
                [--encoder-langtok SRCTGT] [--decoder-langtok]
                [--lang-tok-replacing-bos-eos] [--enable-lang-ids]
                [--enable-reservsed-directions-shared-datasets]
                [--same-lang-per-batch] [--extra-data EXTRA_DATA]
                [--extra-lang-pairs EXTRA_LANG_PAIRS]
                [--fixed-dictionary FIXED_DICTIONARY]
                [--langtoks-specs LANGTOKS_SPECS] [--langtoks LANGTOKS]
                [--sampling-weights-from-file SAMPLING_WEIGHTS_FROM_FILE]
                [--sampling-weights SAMPLING_WEIGHTS]
                [--virtual-epoch-size VIRTUAL_EPOCH_SIZE]
                [--virtual-data-size VIRTUAL_DATA_SIZE]
                [--data-param-list-sampling-ratios DATA_PARAM_LIST_SAMPLING_RATIOS]
                [--slot-method {replace,insert,None}] [--slot-prob SLOT_PROB]
                [--max-slot-num MAX_SLOT_NUM]
                [--max-span-length MAX_SPAN_LENGTH]
                [--subword-prob SUBWORD_PROB]
                [--construct-phrase-level-align-dataset]
                [--sentencepiece-model SENTENCEPIECE_MODEL]
                [--label-smoothing D] [--report-accuracy]
                [--ignore-prefix-size IGNORE_PREFIX_SIZE]
                [--adam-betas ADAM_BETAS] [--adam-eps ADAM_EPS]
                [--weight-decay WEIGHT_DECAY] [--use-old-adam]
                [--warmup-updates WARMUP_UPDATES]
                [--warmup-init-lr WARMUP_INIT_LR] [--pad PAD] [--eos EOS]
                [--unk UNK]
                data
train.py: error: unrecognized arguments: --min-lr 1e-7 --min-lr 1e-7
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 4604) of binary: /usr/bin/python3.7
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 248, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-16_06:56:40
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 2 (pid: 4604)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
2024-04-16 06:57:35 | INFO | fairseq.distributed_utils | distributed init (rank 0): env://
2024-04-16 06:57:35 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-04-16 06:57:35 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2024-04-16 06:57:35 | INFO | fairseq.distributed_utils | initialized host PCR5 as rank 0
2024-04-16 06:57:37 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'simple', 'tensorboard_logdir': None, 'wandb_project': None, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': True}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'broadcast_buffers': False, 'distributed_wrapper': 'DDP', 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0001], 'stop_min_lr': 1e-07, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'path/to/save_dir/', 'restore_file': 'path/to/m2m_checkpoint_baseline-003.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 1024, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': False, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de_big', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'task': Namespace(_name='translation_multi_simple_epoch', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'criterion': Namespace(_name='label_smoothed_cross_entropy', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'path/to/m2m/spm.model'}, 'tokenizer': None}
2024-04-16 06:57:37 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['en', 'ru']
2024-04-16 06:57:37 | INFO | fairseq.data.multilingual.multilingual_data_manager | Loading Dictionary: ['en', 'ru']
2024-04-16 06:57:37 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 256152 types
Traceback (most recent call last):
  File "m2m/train.py", line 14, in <module>
    cli_main()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 409, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/distributed_utils.py", line 354, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/distributed_utils.py", line 332, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 66, in main
    task = tasks.setup_task(cfg.task)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/tasks/__init__.py", line 44, in setup_task
    return task.setup_task(cfg, **kwargs)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/tasks/translation_multi_simple_epoch.py", line 124, in setup_task
    cls.load_dictionary, args, **kwargs
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 472, in prepare
    os.path.join(paths[0], "dict.{}.txt".format(lang))
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/tasks/fairseq_task.py", line 57, in load_dictionary
    return Dictionary.load(filename)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/dictionary.py", line 215, in load
    d.add_from_file(f)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/dictionary.py", line 228, in add_from_file
    raise fnfe
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/dictionary.py", line 225, in add_from_file
    with open(PathManager.get_local_path(f), "r", encoding="utf-8") as fd:
FileNotFoundError: [Errno 2] No such file or directory: 'path/to/langs1/dict.ru.txt'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 4838) of binary: /usr/bin/python3.7
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 248, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-16_06:57:41
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 4838)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
2024-04-16 06:58:52 | INFO | fairseq.distributed_utils | distributed init (rank 0): env://
2024-04-16 06:58:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-04-16 06:58:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2024-04-16 06:58:52 | INFO | fairseq.distributed_utils | initialized host PCR5 as rank 0
2024-04-16 06:58:53 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'simple', 'tensorboard_logdir': None, 'wandb_project': None, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': True}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'broadcast_buffers': False, 'distributed_wrapper': 'DDP', 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1024, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0001], 'stop_min_lr': 1e-07, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'path/to/save_dir/', 'restore_file': 'path/to/m2m_checkpoint_baseline-003.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 1024, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': False, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de_big', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'task': Namespace(_name='translation_multi_simple_epoch', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'criterion': Namespace(_name='label_smoothed_cross_entropy', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=1024, max_tokens_valid=1024, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'path/to/m2m/spm.model'}, 'tokenizer': None}
2024-04-16 06:58:53 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['en', 'ru']
2024-04-16 06:58:53 | INFO | fairseq.data.multilingual.multilingual_data_manager | Loading Dictionary: ['en', 'ru']
2024-04-16 06:58:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 256152 types
2024-04-16 06:58:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | [ru] dictionary: 256152 types
2024-04-16 06:58:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None
2024-04-16 06:58:54 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A
2024-04-16 06:58:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2024-04-16 06:58:54 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {}
Traceback (most recent call last):
  File "m2m/train.py", line 14, in <module>
    cli_main()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 409, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/distributed_utils.py", line 354, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/distributed_utils.py", line 332, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 69, in main
    task.load_dataset(valid_sub_split, combine=False, epoch=1)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/tasks/translation_multi_simple_epoch.py", line 166, in load_dataset
    **kwargs,
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 1399, in load_dataset
    split, training, epoch, combine, shard_epoch, **kwargs
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 1366, in load_sampled_multi_dataset
    split, training, epoch, combine, shard_epoch=shard_epoch, **kwargs
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 1263, in load_split_datasets
    split, epoch, shard_epoch=shard_epoch
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 1158, in get_split_data_param_list
    paths, epoch, shard_epoch, split_num_shards_dict[key]
KeyError: 'main:en-ru'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 5183) of binary: /usr/bin/python3.7
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 248, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-16_06:58:57
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 5183)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
2024-04-16 07:01:44 | INFO | fairseq.distributed_utils | distributed init (rank 0): env://
2024-04-16 07:01:44 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2024-04-16 07:01:44 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
2024-04-16 07:01:44 | INFO | fairseq.distributed_utils | initialized host PCR5 as rank 0
2024-04-16 07:01:45 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'simple', 'tensorboard_logdir': None, 'wandb_project': None, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': True}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'no_c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'fast_stat_sync': False, 'broadcast_buffers': False, 'distributed_wrapper': 'DDP', 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'tpu': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 256, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 256, 'batch_size_valid': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 40000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.0001], 'stop_min_lr': 1e-07, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': 'path/to/save_dir/', 'restore_file': 'path/to/m2m_checkpoint_baseline-003.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': True, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'model_parallel_size': 1, 'distributed_rank': 0}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 1024, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': False, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_wmt_en_de_big', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=256, max_tokens_valid=256, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'task': Namespace(_name='translation_multi_simple_epoch', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=256, max_tokens_valid=256, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'criterion': Namespace(_name='label_smoothed_cross_entropy', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe='sentencepiece', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, construct_phrase_level_align_dataset=False, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='path/to/langs1/:path/to/langs2/', data_buffer_size=10, data_param_list_sampling_ratios=None, dataset_impl=None, ddp_backend='no_c10d', debug=False, decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_langtok=False, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, enable_lang_ids=False, enable_reservsed_directions_shared_datasets=True, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_langtok='src', encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eos=2, extra_data=None, extra_lang_pairs=None, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_dictionary=None, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_inference_langtok=False, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, lang_dict=None, lang_pairs='en-ru,ru-en', lang_tok_replacing_bos_eos=False, lang_tok_style='multilingual', langs=['en', 'ru'], langtoks={'main': ('src', 'tgt')}, langtoks_specs=['main'], layernorm_embedding=False, left_pad_source='False', left_pad_target='False', load_alignments=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_format='simple', log_interval=100, lr=[0.0001], lr_scheduler='inverse_sqrt', max_epoch=10, max_slot_num=14, max_source_positions=1024, max_span_length=256, max_target_positions=1024, max_tokens=256, max_tokens_valid=256, max_update=40000, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_sampling_temperature=1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='path/to/m2m_checkpoint_baseline-003.pt', same_lang_per_batch=False, sampling_method='linear', sampling_temperature=5.0, sampling_weights=None, sampling_weights_from_file=None, save_dir='path/to/save_dir/', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, sentencepiece_model='path/to/m2m/spm.model', shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=True, slot_method='insert', slot_prob=0.85, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_min_lr=1e-07, stop_time_hours=0, subword_prob=0.0, target_lang=None, task='translation_multi_simple_epoch', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=True, unk=3, update_freq=[8], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, virtual_data_size=None, virtual_epoch_size=None, wandb_project=None, warmup_epoch=5, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, zero_sharding='none'), 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'tpu': False, 'lr': [0.0001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': {'_name': 'sentencepiece', 'sentencepiece_model': 'path/to/m2m/spm.model'}, 'tokenizer': None}
2024-04-16 07:01:45 | INFO | fairseq.data.multilingual.multilingual_data_manager | parsed the language list as they are ordered in the option: ['en', 'ru']
2024-04-16 07:01:45 | INFO | fairseq.data.multilingual.multilingual_data_manager | Loading Dictionary: ['en', 'ru']
2024-04-16 07:01:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [en] dictionary: 256152 types
2024-04-16 07:01:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [ru] dictionary: 256152 types
2024-04-16 07:01:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | loading data for valid epoch=1/None
2024-04-16 07:01:46 | INFO | fairseq.tasks.translation_multi_simple_epoch | mem usage: N/A
2024-04-16 07:01:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | langtoks settings: {'main': ('src', 'tgt')}
2024-04-16 07:01:46 | INFO | fairseq.data.multilingual.multilingual_data_manager | [valid] num of shards: {}
Traceback (most recent call last):
  File "m2m/train.py", line 14, in <module>
    cli_main()
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 409, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/distributed_utils.py", line 354, in call_main
    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/distributed_utils.py", line 332, in distributed_main
    main(cfg, **kwargs)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq_cli/train.py", line 69, in main
    task.load_dataset(valid_sub_split, combine=False, epoch=1)
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/tasks/translation_multi_simple_epoch.py", line 166, in load_dataset
    **kwargs,
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 1399, in load_dataset
    split, training, epoch, combine, shard_epoch, **kwargs
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 1366, in load_sampled_multi_dataset
    split, training, epoch, combine, shard_epoch=shard_epoch, **kwargs
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 1263, in load_split_datasets
    split, epoch, shard_epoch=shard_epoch
  File "/mnt/c/Users/Artem/Downloads/CROP-master_/CROP-master/m2m/fairseq/data/multilingual/multilingual_data_manager.py", line 1158, in get_split_data_param_list
    paths, epoch, shard_epoch, split_num_shards_dict[key]
KeyError: 'main:en-ru'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 5906) of binary: /usr/bin/python3.7
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 248, in launch_agent
    failures=result.failures,
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
m2m/train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-16_07:01:50
  host      : PCR5.
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 5906)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
usage: run.py [-h] [--nnodes NNODES] [--nproc_per_node NPROC_PER_NODE]
              [--rdzv_backend RDZV_BACKEND] [--rdzv_endpoint RDZV_ENDPOINT]
              [--rdzv_id RDZV_ID] [--rdzv_conf RDZV_CONF] [--standalone]
              [--max_restarts MAX_RESTARTS]
              [--monitor_interval MONITOR_INTERVAL]
              [--start_method {spawn,fork,forkserver}] [--role ROLE] [-m]
              [--no_python] [--run_path] [--log_dir LOG_DIR] [-r REDIRECTS]
              [-t TEE] [--node_rank NODE_RANK] [--master_addr MASTER_ADDR]
              [--master_port MASTER_PORT]
              training_script ...
run.py: error: argument --node_rank: invalid int value: ''
[E socket.cpp:860] [c10d] The client socket has timed out after 900s while trying to connect to (localhost, 12358).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
TimeoutError: The client socket has timed out after 900s while trying to connect to (localhost, 12358).
[E socket.cpp:860] [c10d] The client socket has timed out after 900s while trying to connect to (localhost, 4567).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
TimeoutError: The client socket has timed out after 900s while trying to connect to (localhost, 4567).
[E socket.cpp:860] [c10d] The client socket has timed out after 900s while trying to connect to (172.18.230.177, 4567).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
TimeoutError: The client socket has timed out after 900s while trying to connect to (172.18.230.177, 4567).
[E socket.cpp:860] [c10d] The client socket has timed out after 900s while trying to connect to (127.0.0.1, 8).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
TimeoutError: The client socket has timed out after 900s while trying to connect to (127.0.0.1, 8).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [PCR5]:8080 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to PCR5:8080 (errno: 110 - Connection timed out).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.1, 8080).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.1, 8080). The client socket has failed to connect to PCR5:8080 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [PCR5]:20 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to PCR5:20 (errno: 110 - Connection timed out).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.1, 20).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.1, 20). The client socket has failed to connect to PCR5:20 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [PCR5]:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.1, 2424).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.1, 2424). The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [PCR5]:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.1, 2424).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.1, 2424). The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [PCR5]:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.1, 2424).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.1, 2424). The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [::ffff:172.18.224.0]:2424 (errno: 113 - No route to host).
[W socket.cpp:601] [c10d] The client socket has failed to connect to 172.18.224.0:2424 (errno: 113 - No route to host).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.0, 2424).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.0, 2424). The client socket has failed to connect to 172.18.224.0:2424 (errno: 113 - No route to host).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [::ffff:172.18.224.0]:13702 (errno: 113 - No route to host).
[W socket.cpp:601] [c10d] The client socket has failed to connect to 172.18.224.0:13702 (errno: 113 - No route to host).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.0, 13702).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.0, 13702). The client socket has failed to connect to 172.18.224.0:13702 (errno: 113 - No route to host).
./pipeline/step0_train_translation_model.sh: line 71: 0d: command not found
[W socket.cpp:601] [c10d] The client socket has failed to connect to [PCR5]:13702 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [PCR5]:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.1, 2424).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.1, 2424). The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to [PCR5]:2424 (errno: 110 - Connection timed out).
[W socket.cpp:601] [c10d] The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
[E socket.cpp:657] [c10d] The client socket has failed to connect to any network address of (172.18.224.1, 2424).
Traceback (most recent call last):
  File "/usr/lib/python3.7/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.7/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 766, in <module>
    main()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/run.py", line 756, in run
    )(*cmd_args)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 844, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 678, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/agent/server/api.py", line 538, in _rendezvous
    store, group_rank, group_world_size = spec.rdzv_handler.next_rendezvous()
  File "/home/artem/.local/lib/python3.7/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 61, in next_rendezvous
    multi_tenant=True,
RuntimeError: The client socket has failed to connect to any network address of (172.18.224.1, 2424). The client socket has failed to connect to PCR5:2424 (errno: 110 - Connection timed out).
